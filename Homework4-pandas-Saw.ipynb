{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - pandas (Saw Sudta)\n",
    "### due 03/10/2021, to be turned on github  \n",
    "\n",
    "<br>\n",
    "\n",
    "Use this notebook and prompts to complete the homework. Throughout there will be hints and code provided to\n",
    "\n",
    "### Things you will need:\n",
    "- Install os, NumPy, pandas\n",
    "- states_covid.csv\n",
    "- Bloom_etal_2018_Reduced_Dataset.csv\n",
    "- logfiles.tgz (or some other multiple file dataset)\n",
    "\n",
    "**hint:** change your working directory to a directory for just this homework. Edit path below and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_dir = \"/Users/chanchanoksudta/Desktop/DataScience2/Data_Science_For_Biology_II/Part.II_PythonProgramming/pandas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chanchanoksudta/Desktop/DataScience2/Data_Science_For_Biology_II/Part.II_PythonProgramming/pandas\n"
     ]
    }
   ],
   "source": [
    "cd $hw_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import packages & check required datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(os.path.join(hw_dir,'states_covid.csv')), 'states_covid.csv does not exist' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(os.path.join(hw_dir,'Bloom_etal_2018_Reduced_Dataset.csv')), 'Bloom_etal_2018_Reduced_Dataset.csv does not exist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x logfiles/\n",
      "x logfiles/1901302136_H15_D_14.txt.txt\n",
      "x logfiles/1901302243_H5_S_14.txt.txt\n",
      "x logfiles/1901302110_H13_S_14.txt.txt\n",
      "x logfiles/1901302121_H8_S_14.txt.txt\n",
      "x logfiles/1901302228_H4_D_14.txt.txt\n",
      "x logfiles/1901302223_H16_S_14.txt.txt\n",
      "x logfiles/1901302117_H15_S_14.txt.txt\n",
      "x logfiles/1901302202_H16_S_14.txt.txt\n",
      "x logfiles/1901302115_H1_S_14.txt.txt\n",
      "x logfiles/1901302158_H9_S_14.txt.txt\n",
      "x logfiles/1901302237_H10_D_14.txt.txt\n",
      "x logfiles/1901302118_H1_D_14.txt.txt\n",
      "x logfiles/1901302120_H5_D_14.txt.txt\n",
      "x logfiles/1901302134_H13_D_14.txt.txt\n",
      "x logfiles/1901302109_H7_S_14.txt.txt\n",
      "x logfiles/1901302236_H17_D_14.txt.txt\n",
      "x logfiles/1901302141_H19_S_14.txt.txt\n",
      "x logfiles/1901302146_H14_D_14.txt.txt\n",
      "x logfiles/1901302137_H18_S_14.txt.txt\n",
      "x logfiles/1901302108_H7_D_14.txt.txt\n",
      "x logfiles/1901302240_H8_D_14.txt.txt\n",
      "x logfiles/1901302212_H9_D_14.txt.txt\n",
      "x logfiles/1901302214_H19_D_14.txt.txt\n",
      "x logfiles/1901302122_H3_D_14.txt.txt\n",
      "x logfiles/1901302138_H11_D_14.txt.txt\n",
      "x logfiles/1901302150_H14_S_14.txt.txt\n",
      "x logfiles/1901302194_H10_S_14.txt.txt\n",
      "x logfiles/1901302217_H18_D_14.txt.txt\n",
      "x logfiles/1901302227_H11_S_14.txt.txt\n",
      "x logfiles/1901302235_H6_S_14.txt.txt\n",
      "x logfiles/1901302203_H7_S_14.txt.txt\n",
      "x logfiles/1901302241_H2_D_14.txt.txt\n",
      "x logfiles/1901302225_H12_D_14.txt.txt\n",
      "x logfiles/1901302119_H4_S_14.txt.txt\n",
      "x logfiles/1901302224_H3_S_14.txt.txt\n",
      "x logfiles/1901302157_H12_S_14.txt.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf logfiles.tgz\n",
    "log_dir = os.path.join(hw_dir,'logfiles')\n",
    "assert os.path.exists(log_dir), 'log_dir does not exist' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - DataFrame manipulation\n",
    "\n",
    "Using **states_covid.csv**, we are going to read the data in as a DataFrame to manipulate, subset, and filter in various ways. \n",
    "\n",
    "**1.1 Read in states_covid.csv with date as a \"date\" dtype, and only columns consisting of the hospitalization (4 col), ICU (2 col), and Ventilators (2 col)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AK</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AL</td>\n",
       "      <td>45250.0</td>\n",
       "      <td>45250.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>122</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AR</td>\n",
       "      <td>14617.0</td>\n",
       "      <td>14617.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AZ</td>\n",
       "      <td>57072.0</td>\n",
       "      <td>57072.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date state  hospitalized  hospitalizedCumulative  \\\n",
       "0 2021-02-23    AK        1260.0                  1260.0   \n",
       "1 2021-02-23    AL       45250.0                 45250.0   \n",
       "2 2021-02-23    AR       14617.0                 14617.0   \n",
       "3 2021-02-23    AS           NaN                     NaN   \n",
       "4 2021-02-23    AZ       57072.0                 57072.0   \n",
       "\n",
       "   hospitalizedCurrently  hospitalizedIncrease  inIcuCumulative  \\\n",
       "0                   38.0                     9              NaN   \n",
       "1                  762.0                   122           2632.0   \n",
       "2                  545.0                    47              NaN   \n",
       "3                    NaN                     0              NaN   \n",
       "4                 1515.0                    78              NaN   \n",
       "\n",
       "   inIcuCurrently  onVentilatorCumulative  onVentilatorCurrently  \n",
       "0             NaN                     NaN                    5.0  \n",
       "1             NaN                  1497.0                    NaN  \n",
       "2           204.0                  1505.0                   99.0  \n",
       "3             NaN                     NaN                    NaN  \n",
       "4           447.0                     NaN                  266.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the states_covid.csv data\n",
    "state_covid_df = pd.read_csv('states_covid.csv') \n",
    "#Subset the data. Here, I include 'state' column in order to be able to use the same subset data to answer following questions\n",
    "state_covid_sub_df = pd.read_csv('states_covid.csv',usecols=['date','state','hospitalized', 'hospitalizedCumulative',\n",
    "       'hospitalizedCurrently', 'hospitalizedIncrease', 'inIcuCumulative',\n",
    "       'inIcuCurrently', 'onVentilatorCumulative', 'onVentilatorCurrently'],parse_dates=['date'],infer_datetime_format=True)\n",
    "#Print the first few rows of the data\n",
    "state_covid_sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 List, in order, the 5 states with the highest numbers of people *currently* hospitalized, in the ICU, and on ventilation**  \n",
    "hint: sort_values, uniqie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56 entries, AK to WY\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   hospitalized_sum            56 non-null     float64\n",
      " 1   hospitalizedCumulative_sum  56 non-null     float64\n",
      " 2   hospitalizedCurrently_sum   56 non-null     float64\n",
      " 3   hospitalizedIncrease_sum    56 non-null     int64  \n",
      " 4   inIcuCumulative_sum         56 non-null     float64\n",
      " 5   inIcuCurrently_sum          56 non-null     float64\n",
      " 6   onVentilatorCumulative_sum  56 non-null     float64\n",
      " 7   onVentilatorCurrently_sum   56 non-null     float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 3.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalized_sum</th>\n",
       "      <th>hospitalizedCumulative_sum</th>\n",
       "      <th>hospitalizedCurrently_sum</th>\n",
       "      <th>hospitalizedIncrease_sum</th>\n",
       "      <th>inIcuCumulative_sum</th>\n",
       "      <th>inIcuCurrently_sum</th>\n",
       "      <th>onVentilatorCumulative_sum</th>\n",
       "      <th>onVentilatorCurrently_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>28486669.0</td>\n",
       "      <td>28486669.0</td>\n",
       "      <td>1550375.0</td>\n",
       "      <td>89995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370858.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>9224730.0</td>\n",
       "      <td>9224730.0</td>\n",
       "      <td>788682.0</td>\n",
       "      <td>63190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>957999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>6734481.0</td>\n",
       "      <td>6734481.0</td>\n",
       "      <td>626423.0</td>\n",
       "      <td>57068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>7233.0</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>693646.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94977.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100077.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hospitalized_sum  hospitalizedCumulative_sum  \\\n",
       "state                                                 \n",
       "NY           28486669.0                  28486669.0   \n",
       "NJ            9224730.0                   9224730.0   \n",
       "IL                  0.0                         0.0   \n",
       "AZ            6734481.0                   6734481.0   \n",
       "PA               7233.0                      7233.0   \n",
       "\n",
       "       hospitalizedCurrently_sum  hospitalizedIncrease_sum  \\\n",
       "state                                                        \n",
       "NY                     1550375.0                     89995   \n",
       "NJ                      788682.0                     63190   \n",
       "IL                      957999.0                         0   \n",
       "AZ                      626423.0                     57068   \n",
       "PA                      693646.0                         0   \n",
       "\n",
       "       inIcuCumulative_sum  inIcuCurrently_sum  onVentilatorCumulative_sum  \\\n",
       "state                                                                        \n",
       "NY                     0.0            370858.0                         0.0   \n",
       "NJ                     0.0            171194.0                         0.0   \n",
       "IL                     0.0            221916.0                         0.0   \n",
       "AZ                     0.0            168356.0                         0.0   \n",
       "PA                     0.0             94977.0                         0.0   \n",
       "\n",
       "       onVentilatorCurrently_sum  \n",
       "state                             \n",
       "NY                      131652.0  \n",
       "NJ                      120206.0  \n",
       "IL                      118938.0  \n",
       "AZ                      109908.0  \n",
       "PA                      100077.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort dataframe \n",
    "#Use 'state_covid_sub_df'\n",
    "#The 5 states with the highest numbers of people currently hospitalized\n",
    "covid_df_state = state_covid_sub_df.groupby('state',as_index=False).agg(['sum'])\n",
    "covid_df_state.head()\n",
    "#join multiindex column name with actual column name\n",
    "covid_df_state.columns = covid_df_state.columns.map('_'.join)\n",
    "covid_df_state.head()\n",
    "#list states \n",
    "covid_df_state.info()  #check column names\n",
    "covid_df_state.sort_values('hospitalizedCurrently_sum',ascending=False,inplace=True)\n",
    "covid_df_state.head()\n",
    "### Answer: the first 5 states with the highest numbers of people currently hostpitalized are\n",
    "### CA, TX,NY, FL, and IL, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalized_sum</th>\n",
       "      <th>hospitalizedCumulative_sum</th>\n",
       "      <th>hospitalizedCurrently_sum</th>\n",
       "      <th>hospitalizedIncrease_sum</th>\n",
       "      <th>inIcuCumulative_sum</th>\n",
       "      <th>inIcuCurrently_sum</th>\n",
       "      <th>onVentilatorCumulative_sum</th>\n",
       "      <th>onVentilatorCurrently_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2588299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>650791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2062892.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493582.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>28486669.0</td>\n",
       "      <td>28486669.0</td>\n",
       "      <td>1550375.0</td>\n",
       "      <td>89995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370858.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>957999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>9224730.0</td>\n",
       "      <td>9224730.0</td>\n",
       "      <td>788682.0</td>\n",
       "      <td>63190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120206.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hospitalized_sum  hospitalizedCumulative_sum  \\\n",
       "state                                                 \n",
       "CA                  0.0                         0.0   \n",
       "TX                  0.0                         0.0   \n",
       "NY           28486669.0                  28486669.0   \n",
       "IL                  0.0                         0.0   \n",
       "NJ            9224730.0                   9224730.0   \n",
       "\n",
       "       hospitalizedCurrently_sum  hospitalizedIncrease_sum  \\\n",
       "state                                                        \n",
       "CA                     2588299.0                         0   \n",
       "TX                     2062892.0                         0   \n",
       "NY                     1550375.0                     89995   \n",
       "IL                      957999.0                         0   \n",
       "NJ                      788682.0                     63190   \n",
       "\n",
       "       inIcuCumulative_sum  inIcuCurrently_sum  onVentilatorCumulative_sum  \\\n",
       "state                                                                        \n",
       "CA                     0.0            650791.0                         0.0   \n",
       "TX                     0.0            493582.0                         0.0   \n",
       "NY                     0.0            370858.0                         0.0   \n",
       "IL                     0.0            221916.0                         0.0   \n",
       "NJ                     0.0            171194.0                         0.0   \n",
       "\n",
       "       onVentilatorCurrently_sum  \n",
       "state                             \n",
       "CA                           0.0  \n",
       "TX                           0.0  \n",
       "NY                      131652.0  \n",
       "IL                      118938.0  \n",
       "NJ                      120206.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in the ICU\n",
    "covid_df_state.sort_values('inIcuCurrently_sum',ascending=False,inplace=True)\n",
    "covid_df_state.head()\n",
    "### Answer: the first 5 states with the highest numbers of people currently in the ICU are\n",
    "### CA, TX, NY, IL, and NJ, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalized_sum</th>\n",
       "      <th>hospitalizedCumulative_sum</th>\n",
       "      <th>hospitalizedCurrently_sum</th>\n",
       "      <th>hospitalizedIncrease_sum</th>\n",
       "      <th>inIcuCumulative_sum</th>\n",
       "      <th>inIcuCurrently_sum</th>\n",
       "      <th>onVentilatorCumulative_sum</th>\n",
       "      <th>onVentilatorCurrently_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>28486669.0</td>\n",
       "      <td>28486669.0</td>\n",
       "      <td>1550375.0</td>\n",
       "      <td>89995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370858.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>9224730.0</td>\n",
       "      <td>9224730.0</td>\n",
       "      <td>788682.0</td>\n",
       "      <td>63190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>957999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>6734481.0</td>\n",
       "      <td>6734481.0</td>\n",
       "      <td>626423.0</td>\n",
       "      <td>57068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>7233.0</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>693646.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94977.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100077.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hospitalized_sum  hospitalizedCumulative_sum  \\\n",
       "state                                                 \n",
       "NY           28486669.0                  28486669.0   \n",
       "NJ            9224730.0                   9224730.0   \n",
       "IL                  0.0                         0.0   \n",
       "AZ            6734481.0                   6734481.0   \n",
       "PA               7233.0                      7233.0   \n",
       "\n",
       "       hospitalizedCurrently_sum  hospitalizedIncrease_sum  \\\n",
       "state                                                        \n",
       "NY                     1550375.0                     89995   \n",
       "NJ                      788682.0                     63190   \n",
       "IL                      957999.0                         0   \n",
       "AZ                      626423.0                     57068   \n",
       "PA                      693646.0                         0   \n",
       "\n",
       "       inIcuCumulative_sum  inIcuCurrently_sum  onVentilatorCumulative_sum  \\\n",
       "state                                                                        \n",
       "NY                     0.0            370858.0                         0.0   \n",
       "NJ                     0.0            171194.0                         0.0   \n",
       "IL                     0.0            221916.0                         0.0   \n",
       "AZ                     0.0            168356.0                         0.0   \n",
       "PA                     0.0             94977.0                         0.0   \n",
       "\n",
       "       onVentilatorCurrently_sum  \n",
       "state                             \n",
       "NY                      131652.0  \n",
       "NJ                      120206.0  \n",
       "IL                      118938.0  \n",
       "AZ                      109908.0  \n",
       "PA                      100077.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on ventilation\n",
    "covid_df_state.sort_values('onVentilatorCurrently_sum',ascending=False,inplace=True)\n",
    "covid_df_state.head()\n",
    "### Answer: the first 5 states with the highest numbers of people currently on ventilation are\n",
    "### NY, NJ, IL, AZ, and PA, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Identify the date for each state where the cumulative hosipitalized was greater than or equal to 1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20108 entries, 2637 to 20107\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   date                    20108 non-null  datetime64[ns]\n",
      " 1   state                   20108 non-null  object        \n",
      " 2   hospitalized            12435 non-null  float64       \n",
      " 3   hospitalizedCumulative  12435 non-null  float64       \n",
      " 4   hospitalizedCurrently   16702 non-null  float64       \n",
      " 5   hospitalizedIncrease    20108 non-null  int64         \n",
      " 6   inIcuCumulative         3648 non-null   float64       \n",
      " 7   inIcuCurrently          11030 non-null  float64       \n",
      " 8   onVentilatorCumulative  1245 non-null   float64       \n",
      " 9   onVentilatorCurrently   8738 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17733</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>NY</td>\n",
       "      <td>52936.0</td>\n",
       "      <td>52936.0</td>\n",
       "      <td>18825.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17789</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>NY</td>\n",
       "      <td>50919.0</td>\n",
       "      <td>50919.0</td>\n",
       "      <td>18707.0</td>\n",
       "      <td>2622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17677</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>NY</td>\n",
       "      <td>54653.0</td>\n",
       "      <td>54653.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>1717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17845</th>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>NY</td>\n",
       "      <td>48297.0</td>\n",
       "      <td>48297.0</td>\n",
       "      <td>18654.0</td>\n",
       "      <td>2529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17901</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>NY</td>\n",
       "      <td>45768.0</td>\n",
       "      <td>45768.0</td>\n",
       "      <td>18569.0</td>\n",
       "      <td>2916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18241</th>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>PA</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18266</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>FL</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18267</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>GA</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18322</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>FL</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18323</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>GA</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9308 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date state  hospitalized  hospitalizedCumulative  \\\n",
       "17733 2020-04-13    NY       52936.0                 52936.0   \n",
       "17789 2020-04-12    NY       50919.0                 50919.0   \n",
       "17677 2020-04-14    NY       54653.0                 54653.0   \n",
       "17845 2020-04-11    NY       48297.0                 48297.0   \n",
       "17901 2020-04-10    NY       45768.0                 45768.0   \n",
       "...          ...   ...           ...                     ...   \n",
       "18241 2020-04-04    PA        1004.0                  1004.0   \n",
       "18266 2020-04-03    FL        1287.0                  1287.0   \n",
       "18267 2020-04-03    GA        1158.0                  1158.0   \n",
       "18322 2020-04-02    FL        1123.0                  1123.0   \n",
       "18323 2020-04-02    GA        1056.0                  1056.0   \n",
       "\n",
       "       hospitalizedCurrently  hospitalizedIncrease  inIcuCumulative  \\\n",
       "17733                18825.0                  2017              NaN   \n",
       "17789                18707.0                  2622              NaN   \n",
       "17677                18697.0                  1717              NaN   \n",
       "17845                18654.0                  2529              NaN   \n",
       "17901                18569.0                  2916              NaN   \n",
       "...                      ...                   ...              ...   \n",
       "18241                    NaN                   152              NaN   \n",
       "18266                    NaN                   164              NaN   \n",
       "18267                    NaN                   102              NaN   \n",
       "18322                    NaN                   174              NaN   \n",
       "18323                    NaN                   104              NaN   \n",
       "\n",
       "       inIcuCurrently  onVentilatorCumulative  onVentilatorCurrently  \n",
       "17733          5156.0                     NaN                    NaN  \n",
       "17789          5198.0                     NaN                    NaN  \n",
       "17677          5225.0                     NaN                    NaN  \n",
       "17845          5009.0                     NaN                    NaN  \n",
       "17901          4908.0                     NaN                    NaN  \n",
       "...               ...                     ...                    ...  \n",
       "18241             NaN                     NaN                    NaN  \n",
       "18266             NaN                     NaN                    NaN  \n",
       "18267             NaN                     NaN                    NaN  \n",
       "18322             NaN                     NaN                    NaN  \n",
       "18323             NaN                     NaN                    NaN  \n",
       "\n",
       "[9308 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall column names\n",
    "state_covid_sub_df.info()\n",
    "#Identify the date where the cumulative hosipitalized was greater than or equal to 1000\n",
    "state_covid_sub_df[(state_covid_sub_df.hospitalizedCumulative >= 1000)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - DataFrame summarizing\n",
    "\n",
    "Using **Bloom_etal_2018_Reduced_Dataset.csv**, we are going to do more dataframe manipulation and subsetting and summarizing  \n",
    "\n",
    "**2.1 Read in Bloom_etal_2018_Reduced_Dataset.csv and create two new columns ('genus','species') that consists of the column *taxa* split at the underscore. Print out the head of this new dataframe and the number of unique genera**   \n",
    "\n",
    "*hint:* pd.str.split(,expand=True)\n",
    "\n",
    "for example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| taxa | genus | species \n",
    "| :------ | :-- | :--- \n",
    "| Alosa_alabamae | Alosa | alabamae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxa</th>\n",
       "      <th>logbodysize</th>\n",
       "      <th>trophic_position</th>\n",
       "      <th>Reg</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alosa_alabamae</td>\n",
       "      <td>1.707570</td>\n",
       "      <td>0.431364</td>\n",
       "      <td>diadromous</td>\n",
       "      <td>Alosa</td>\n",
       "      <td>alabamae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alosa_alosa</td>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>diadromous</td>\n",
       "      <td>Alosa</td>\n",
       "      <td>alosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alosa_fallax</td>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>diadromous</td>\n",
       "      <td>Alosa</td>\n",
       "      <td>fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alosa_mediocris</td>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.612784</td>\n",
       "      <td>diadromous</td>\n",
       "      <td>Alosa</td>\n",
       "      <td>mediocris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alosa_pseudoharengus</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.544068</td>\n",
       "      <td>diadromous</td>\n",
       "      <td>Alosa</td>\n",
       "      <td>pseudoharengus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   taxa  logbodysize  trophic_position         Reg  genus  \\\n",
       "0        Alosa_alabamae     1.707570          0.431364  diadromous  Alosa   \n",
       "1           Alosa_alosa     1.778151          0.556303  diadromous  Alosa   \n",
       "2          Alosa_fallax     1.778151          0.556303  diadromous  Alosa   \n",
       "3       Alosa_mediocris     1.778151          0.612784  diadromous  Alosa   \n",
       "4  Alosa_pseudoharengus     1.602060          0.544068  diadromous  Alosa   \n",
       "\n",
       "          species  \n",
       "0        alabamae  \n",
       "1           alosa  \n",
       "2          fallax  \n",
       "3       mediocris  \n",
       "4  pseudoharengus  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data frame 'Bloom_etal_2018_Reduced_Dataset.csv'\n",
    "Bloom = pd.read_csv('Bloom_etal_2018_Reduced_Dataset.csv')\n",
    "#Print the entire data set to see overal data\n",
    "Bloom\n",
    "\n",
    "#split taxa by '_' and store the fraction of the string in two new columns ('genus','species')\n",
    "Bloom[['genus','species']] = Bloom.taxa.str.split(\"_\",1, expand=True) \n",
    "## note'1' in str.split indicates that split will happen once to separte genus and species\n",
    "## I added this maxsplit because some taxa (name) has more than one '_'.\n",
    "Bloom.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique genera \n",
    "len(Bloom.genus.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Create a new dataframe with the mean *logbodysize* and *trophicposition* of each genera. Sort this data frame by the largest body size. Print the head of this dataframe. Which genera is the smallest and largest? What is the trophic position of the smallest and largest?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logbodysize</th>\n",
       "      <th>trophic_position</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tenualosa</th>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.462398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alosa</th>\n",
       "      <td>1.739062</td>\n",
       "      <td>0.540815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coilia</th>\n",
       "      <td>1.544068</td>\n",
       "      <td>0.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethmalosa</th>\n",
       "      <td>1.544068</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potamalosa</th>\n",
       "      <td>1.505150</td>\n",
       "      <td>0.518514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            logbodysize  trophic_position\n",
       "genus                                    \n",
       "Tenualosa      1.778151          0.462398\n",
       "Alosa          1.739062          0.540815\n",
       "Coilia         1.544068          0.477121\n",
       "Ethmalosa      1.544068          0.397940\n",
       "Potamalosa     1.505150          0.518514"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new data frame with the mean ...\n",
    "#create a new dataframe that has only genus, logbodysize, and trophic_position\n",
    "new_df = Bloom[['genus','logbodysize','trophic_position']].copy()\n",
    "#find the means using .mean()\n",
    "new_df = new_df.groupby('genus').mean()\n",
    "new_df\n",
    "#sort the dataframe by the largest body size\n",
    "#sort from largest to smallest size\n",
    "new_df.sort_values('logbodysize',ascending=False,inplace=True)\n",
    "new_df.head()\n",
    "\n",
    "#Answer: Tenualosa is the largest, with the trophic position of 0.4624."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logbodysize</th>\n",
       "      <th>trophic_position</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amazonsprattus</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.531479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sundasalanx</th>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.491362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sierrathrissa</th>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.491362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clupeichthys</th>\n",
       "      <td>0.602060</td>\n",
       "      <td>0.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauvagella</th>\n",
       "      <td>0.672098</td>\n",
       "      <td>0.491362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                logbodysize  trophic_position\n",
       "genus                                        \n",
       "Amazonsprattus     0.301030          0.531479\n",
       "Sundasalanx        0.447158          0.491362\n",
       "Sierrathrissa      0.477121          0.491362\n",
       "Clupeichthys       0.602060          0.477121\n",
       "Sauvagella         0.672098          0.491362"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the dataframe by the smallest size\n",
    "new_df.sort_values('logbodysize',ascending=True,inplace=True)\n",
    "new_df.head()\n",
    "\n",
    "#Answer: Amazonsprattus is the smallest, with the trophic position of 0.5315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Read in muliple files to a dictionary and make a DataFrame\n",
    "\n",
    "### This is not an easy excersize. You will have some example code to start but the rest is up to you. You have done all these parts before so should just be linking them together\n",
    "\n",
    "Using **logfiles**: we are going to do read in each file, get some data, append it to a dictionary to later make into a dataframe. \n",
    "\n",
    "First step is to find the necessary files. The number of files in the log files is 36, make sure you have that many as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      36\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l logfiles/*txt | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chanchanoksudta/Desktop/DataScience2/Data_Science_For_Biology_II/Part.II_PythonProgramming/pandas\n"
     ]
    }
   ],
   "source": [
    "cd $hw_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chanchanoksudta/Desktop/DataScience2/Data_Science_For_Biology_II/Part.II_PythonProgramming/pandas/logfiles/1901302235_H6_S_14.txt.txt\n"
     ]
    }
   ],
   "source": [
    "logfiles = !find ./logfiles -name \"*txt\" #unix command to find files\n",
    "logfiles = [os.path.abspath(x) for x in logfiles] #this finds the full path to the file\n",
    "print(logfiles[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(logfiles)==36), 'Do not have correct number of logfiles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a little tricky here\n",
    "\n",
    "Read in each of the logfiles, for each file extract:\n",
    "- minimum temperature\n",
    "- maximum temperature\n",
    "- date of minimum temp \n",
    "- date of maximum temp \n",
    "- mean temp for each file. \n",
    "\n",
    "This data should all be appended for a dictionary within a for loop:    \n",
    "Key should be the file name without the path or .txt extension  \n",
    "Values should be (minTemp,maxTemp,minDate,maxDate,meanTemp)\n",
    "\n",
    "I recommend making this work for one file first, then putting the rest in a for loop to do the rest.  \n",
    "\n",
    "Below is an example of how to read in one file\n",
    "\n",
    "*hint:* do not read date in as date object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>8:00:00 AM</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>8:35:00 AM</td>\n",
       "      <td>48.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>9:10:00 AM</td>\n",
       "      <td>48.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>9:45:00 AM</td>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>10:20:00 AM</td>\n",
       "      <td>50.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date         Time  Temp\n",
       "0  9/16/2013   8:00:00 AM  47.9\n",
       "1  9/16/2013   8:35:00 AM  48.2\n",
       "2  9/16/2013   9:10:00 AM  48.7\n",
       "3  9/16/2013   9:45:00 AM  49.4\n",
       "4  9/16/2013  10:20:00 AM  50.3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### set up data frame as you read in each file\n",
    "infile = pd.read_csv(logfiles[0],sep='\\t',engine='python')\n",
    "infile.columns = ['Index','Date','Time','Temp','Type']\n",
    "infile = infile[['Date','Time','Temp']]\n",
    "infile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do everything in steps, make sure it works. Calculate summaries with this one infile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minTemp =   \n",
    "maxTemp =  \n",
    "minDate = infile['Date'][infile['Temp'] == infile['Temp'].min()].unique()[0] #use this for minDate,maxDate  \n",
    "maxDate =   \n",
    "meanTemp =   `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get you started, I suggest writing some dummy code in plain words to help outline your for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfiles_dict = {}  #empty dictionary\n",
    "for f in logfiles:  \n",
    "    #assign a file name to a key (how?)\n",
    "        #Key is the file name without the path or .txt extension\n",
    "        \n",
    "    #do something \n",
    "        #read each data frame at a time,\n",
    "        #read each column, \n",
    "        #and subset only necesary columns \n",
    "        #do not read date in as date object  \n",
    "    #do more something   \n",
    "        #do calculations here\n",
    "        #minTemp = infile['Temp'].min()[0]\n",
    "        #maxTemp = infile['Temp'].max()[0]\n",
    "        #minDate = infile['Date'][infile['Temp'] == infile['Temp'].min()].unique()[0]\n",
    "        #maxDate = infile['Date'][infile['Temp'] == infile['Temp'].max()].unique()[0]\n",
    "        #meanTemp = infile['Temp'].mean()[0]\n",
    "    #make print statements EVERYWHERE  \n",
    "    #append to dict  \n",
    "    #blahbahblah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chanchanoksudta/Desktop/DataScience2/Data_Science_For_Biology_II/Part.II_PythonProgramming/pandas/logfiles/1901302235_H6_S_14.txt.txt'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print logfiles\n",
    "logfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1901302235_H6_S_14'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract file name \n",
    "#test a script to remove absolute path and file extension\n",
    "filename=os.path.basename(logfiles[0])\n",
    "filename\n",
    "os.path.splitext(filename)\n",
    "filename1 = os.path.splitext(filename)[0]\n",
    "filename1 = str(filename1).replace(\".txt\",\"\")\n",
    "filename1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1901302235_H6_S_14': [21.3,\n",
       "  65.8,\n",
       "  array(['12/6/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.726191321640705]}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if the script works\n",
    "#read the file\n",
    "infile = pd.read_csv(logfiles[0],sep='\\t',engine='python')\n",
    "infile.columns = ['Index','Date','Time','Temp','Type']\n",
    "infile = infile[['Date','Time','Temp']]\n",
    "infile.head()\n",
    "#add calcuations and save the new values to the value of the key\n",
    "minTemp = infile['Temp'].min()\n",
    "maxTemp = infile['Temp'].max()\n",
    "minDate = infile['Date'][infile['Temp'] == infile['Temp'].min()].unique()\n",
    "maxDate = infile['Date'][infile['Temp'] == infile['Temp'].max()].unique()\n",
    "meanTemp = infile['Temp'].mean()\n",
    "values = [minTemp, maxTemp, minDate, maxDate, meanTemp]\n",
    "\n",
    "#add key and values to the dictionary\n",
    "logfiles_dict[key] = values\n",
    "logfiles_dict\n",
    "#this works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do the real code below here. You don't need to turnin your thoughts. Just put it in there as a help reminder. Most people all still do this, no matter how advanced they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1901302235_H6_S_14': [21.3,\n",
       "  65.8,\n",
       "  array(['12/6/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.726191321640705],\n",
       " '1901302121_H8_S_14': [17.9,\n",
       "  73.4,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  34.698865895869396],\n",
       " '1901302217_H18_D_14': [21.0,\n",
       "  82.4,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/26/2014'], dtype=object),\n",
       "  33.334564066359555],\n",
       " '1901302110_H13_S_14': [22.8,\n",
       "  60.9,\n",
       "  array(['10/4/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  32.24003248358139],\n",
       " '1901302146_H14_D_14': [24.6,\n",
       "  66.1,\n",
       "  array(['1/21/2014', '1/22/2014', '1/23/2014'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  34.24207513941743],\n",
       " '1901302240_H8_D_14': [21.4,\n",
       "  81.3,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.993644598273534],\n",
       " '1901302109_H7_S_14': [20.8,\n",
       "  89.4,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/2/2014'], dtype=object),\n",
       "  36.524380044018045],\n",
       " '1901302150_H14_S_14': [19.4,\n",
       "  70.5,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  34.403639565600834],\n",
       " '1901302141_H19_S_14': [19.4,\n",
       "  71.8,\n",
       "  array(['1/23/2014'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  39.46768146678488],\n",
       " '1901302241_H2_D_14': [25.9,\n",
       "  69.4,\n",
       "  array(['11/16/2013'], dtype=object),\n",
       "  array(['9/15/2013'], dtype=object),\n",
       "  34.88492985687798],\n",
       " '1901302194_H10_S_14': [22.3,\n",
       "  66.8,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.49852380279647],\n",
       " '1901302227_H11_S_14': [22.2,\n",
       "  104.2,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/14/2014'], dtype=object),\n",
       "  36.21180917431059],\n",
       " '1901302136_H15_D_14': [23.0,\n",
       "  91.4,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/27/2014'], dtype=object),\n",
       "  35.291187261523454],\n",
       " '1901302223_H16_S_14': [25.3,\n",
       "  63.9,\n",
       "  array(['10/4/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.50903954802164],\n",
       " '1901302243_H5_S_14': [21.5,\n",
       "  68.4,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.30480789716791],\n",
       " '1901302122_H3_D_14': [27.4,\n",
       "  64.3,\n",
       "  array(['11/5/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  37.571647727272186],\n",
       " '1901302202_H16_S_14': [20.0,\n",
       "  65.7,\n",
       "  array(['2/5/2014'], dtype=object),\n",
       "  array(['7/13/2014', '7/19/2014'], dtype=object),\n",
       "  34.28004255631336],\n",
       " '1901302236_H17_D_14': [22.3,\n",
       "  65.0,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/26/2014'], dtype=object),\n",
       "  35.91733802920407],\n",
       " '1901302158_H9_S_14': [21.2,\n",
       "  71.8,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.16926750422685],\n",
       " '1901302225_H12_D_14': [22.1,\n",
       "  63.9,\n",
       "  array(['10/16/2013'], dtype=object),\n",
       "  array(['7/14/2014'], dtype=object),\n",
       "  34.060063559319694],\n",
       " '1901302120_H5_D_14': [22.7,\n",
       "  63.9,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  35.31249201051068],\n",
       " '1901302118_H1_D_14': [27.0,\n",
       "  86.3,\n",
       "  array(['10/16/2013', '11/18/2013'], dtype=object),\n",
       "  array(['9/15/2013'], dtype=object),\n",
       "  35.60352866151906],\n",
       " '1901302203_H7_S_14': [21.8,\n",
       "  63.0,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  32.955576880489446],\n",
       " '1901302119_H4_S_14': [20.7,\n",
       "  73.7,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['6/30/2014'], dtype=object),\n",
       "  35.1503267045429],\n",
       " '1901302212_H9_D_14': [22.3,\n",
       "  62.7,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/14/2014'], dtype=object),\n",
       "  34.514721260770244],\n",
       " '1901302108_H7_D_14': [24.9,\n",
       "  52.2,\n",
       "  array(['11/5/2013'], dtype=object),\n",
       "  array(['7/26/2014', '7/27/2014'], dtype=object),\n",
       "  32.7065771019398],\n",
       " '1901302224_H3_S_14': [21.3,\n",
       "  108.0,\n",
       "  array(['9/27/2013'], dtype=object),\n",
       "  array(['6/30/2014'], dtype=object),\n",
       "  38.74253551136267],\n",
       " '1901302237_H10_D_14': [24.4,\n",
       "  73.2,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/24/2014'], dtype=object),\n",
       "  35.807603621446034],\n",
       " '1901302117_H15_S_14': [23.7,\n",
       "  67.5,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  34.974126797766935],\n",
       " '1901302137_H18_S_14': [20.3,\n",
       "  62.1,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014', '7/27/2014'], dtype=object),\n",
       "  33.210540063536214],\n",
       " '1901302214_H19_D_14': [21.6,\n",
       "  69.8,\n",
       "  array(['1/27/2014'], dtype=object),\n",
       "  array(['9/2/2014'], dtype=object),\n",
       "  39.63558869809211],\n",
       " '1901302134_H13_D_14': [24.0,\n",
       "  50.0,\n",
       "  array(['9/27/2013'], dtype=object),\n",
       "  array(['7/26/2014'], dtype=object),\n",
       "  31.98697217907111],\n",
       " '1901302157_H12_S_14': [17.8,\n",
       "  75.8,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  34.58131487889515],\n",
       " '1901302138_H11_D_14': [24.6,\n",
       "  78.6,\n",
       "  array(['10/28/2013'], dtype=object),\n",
       "  array(['7/2/2014'], dtype=object),\n",
       "  35.34067522935687],\n",
       " '1901302228_H4_D_14': [23.6,\n",
       "  64.1,\n",
       "  array(['11/5/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  34.80269176136048],\n",
       " '1901302115_H1_S_14': [23.2,\n",
       "  79.8,\n",
       "  array(['10/16/2013'], dtype=object),\n",
       "  array(['7/13/2014'], dtype=object),\n",
       "  36.58338660416422]}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##adding key and value to a dictionary\n",
    "#an empty dictionary\n",
    "logfiles_dict = {} \n",
    "#for loop should start here\n",
    "for f in logfiles: \n",
    "    #extract file name\n",
    "    filename=os.path.basename(f)\n",
    "    #filename\n",
    "    os.path.splitext(filename)[0]\n",
    "    filename1 = os.path.splitext(filename)[0]\n",
    "    filename1 = str(filename1).replace(\".txt\",\"\")\n",
    "    filename1\n",
    "    #key is the file name\n",
    "    key = filename1\n",
    "    #read the file\n",
    "    infile = pd.read_csv(f,sep='\\t',engine='python')\n",
    "    infile.columns = ['Index','Date','Time','Temp','Type']\n",
    "    infile = infile[['Date','Time','Temp']]\n",
    "    infile.head()\n",
    "    #add calcuations and save the new values to the value of the key\n",
    "    minTemp = infile['Temp'].min()\n",
    "    maxTemp = infile['Temp'].max()\n",
    "    minDate = infile['Date'][infile['Temp'] == infile['Temp'].min()].unique()\n",
    "    maxDate = infile['Date'][infile['Temp'] == infile['Temp'].max()].unique()\n",
    "    meanTemp = infile['Temp'].mean()\n",
    "    values = [minTemp, maxTemp, minDate, maxDate, meanTemp]\n",
    "    #add key and values to the dictionary\n",
    "    logfiles_dict[key] = values\n",
    "    logfiles_dict.update()  #.update will append data\n",
    "\n",
    "#print a dictionary\n",
    "logfiles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minTemp</th>\n",
       "      <th>maxTemp</th>\n",
       "      <th>minDate</th>\n",
       "      <th>maxDate</th>\n",
       "      <th>meanTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901302235_H6_S_14</th>\n",
       "      <td>21.3</td>\n",
       "      <td>65.8</td>\n",
       "      <td>[12/6/2013]</td>\n",
       "      <td>[7/13/2014]</td>\n",
       "      <td>35.7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901302121_H8_S_14</th>\n",
       "      <td>17.9</td>\n",
       "      <td>73.4</td>\n",
       "      <td>[10/28/2013]</td>\n",
       "      <td>[7/13/2014]</td>\n",
       "      <td>34.6989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901302217_H18_D_14</th>\n",
       "      <td>21</td>\n",
       "      <td>82.4</td>\n",
       "      <td>[10/28/2013]</td>\n",
       "      <td>[7/26/2014]</td>\n",
       "      <td>33.3346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901302110_H13_S_14</th>\n",
       "      <td>22.8</td>\n",
       "      <td>60.9</td>\n",
       "      <td>[10/4/2013]</td>\n",
       "      <td>[7/13/2014]</td>\n",
       "      <td>32.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901302146_H14_D_14</th>\n",
       "      <td>24.6</td>\n",
       "      <td>66.1</td>\n",
       "      <td>[1/21/2014, 1/22/2014, 1/23/2014]</td>\n",
       "      <td>[7/13/2014]</td>\n",
       "      <td>34.2421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    minTemp maxTemp                            minDate  \\\n",
       "1901302235_H6_S_14     21.3    65.8                        [12/6/2013]   \n",
       "1901302121_H8_S_14     17.9    73.4                       [10/28/2013]   \n",
       "1901302217_H18_D_14      21    82.4                       [10/28/2013]   \n",
       "1901302110_H13_S_14    22.8    60.9                        [10/4/2013]   \n",
       "1901302146_H14_D_14    24.6    66.1  [1/21/2014, 1/22/2014, 1/23/2014]   \n",
       "\n",
       "                         maxDate meanTemp  \n",
       "1901302235_H6_S_14   [7/13/2014]  35.7262  \n",
       "1901302121_H8_S_14   [7/13/2014]  34.6989  \n",
       "1901302217_H18_D_14  [7/26/2014]  33.3346  \n",
       "1901302110_H13_S_14  [7/13/2014]    32.24  \n",
       "1901302146_H14_D_14  [7/13/2014]  34.2421  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change a dictionary to dataframe\n",
    "summary_df = pd.DataFrame.from_dict(logfiles_dict)\n",
    "#assign column numbers based on the order of calculation from the for loop\n",
    "summary_df.index =['minTemp','maxTemp','minDate','maxDate','meanTemp']\n",
    "#print the head\n",
    "summary_df.head()\n",
    "\n",
    "#I don't linke how the current table is formatted. I want to swap rows and columns\n",
    "summary_df_t = summary_df.transpose()\n",
    "summary_df_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you have created a DataFrame with all the logfiles, print the head and save it to an outfile using pd.to_csv() as logfiles_df.csv** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the head of the new dataframe\n",
    "summary_df_t.head()\n",
    "summary_df_t.to_csv('logfiles_df.csv')\n",
    "\n",
    "#DONE!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
